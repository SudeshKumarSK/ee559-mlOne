{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework : 5 Machine Learning - 1 (Supervised Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] (d) 2-class MSE Classifier with Regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.linearRegression import Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the train and test datasets using pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./datasets/train.csv\", header=None)\n",
    "print(\"Train Data -> 1: \")\n",
    "print(train_data.head())\n",
    "print()\n",
    "\n",
    "test_data = pd.read_csv(\"./datasets/test.csv\", header=None)\n",
    "print(\"Test Data -> 1: \")\n",
    "print(test_data.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an instance for the Regressor class in utils.LinearRegression library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Regressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) i] Code a MSE classifier with 7 different degrees of polynomial (ùëù = 1,2,3,4,5,6,7). As a baseline, do not use any regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, X_train, T_train = regressor.generateTrainData(trainData=train_data, printFlag=True)\n",
    "n_test, X_test, T_test  = regressor.generateTestData(testData = test_data, printFlag=True)\n",
    "\n",
    "T_train_changed = regressor.changeLabels(T = T_train, n =  n_train)\n",
    "T_test_changed = regressor.changeLabels(T = T_test, n =  n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing non-linear transfromation on the train and test data for p = 1, 2, 3, 4, 5, 6, 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p1 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=1, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p1 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=1, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p2 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=2, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p2 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=2, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p3 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=3, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p3 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=3, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p4 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=4, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p4 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=4, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p5 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=5, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p5 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=5, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p6 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=6, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p6 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=6, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n",
    "\n",
    "\n",
    "X_train_p7 = regressor.generatePolynomialFeatures(X = X_train, n = n_train, degree=7, datasetName = \"Train Data\", printFlag=True)\n",
    "X_test_p7 = regressor.generatePolynomialFeatures(X = X_test, n = n_test, degree=7, datasetName = \"Test Data\", printFlag=True)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model using sklearn's Linear Regression Class for lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 1\n",
    "model_p1, w_vector_1 = regressor.modelTrain(X_train = X_train_p1, T_train = T_train_changed)\n",
    "\n",
    "# p = 2\n",
    "model_p2, w_vector_2 = regressor.modelTrain(X_train = X_train_p2, T_train = T_train_changed)\n",
    "\n",
    "# p = 3\n",
    "model_p3, w_vector_3 = regressor.modelTrain(X_train = X_train_p3, T_train = T_train_changed)\n",
    "\n",
    "# p = 4\n",
    "model_p4, w_vector_4 = regressor.modelTrain(X_train = X_train_p4, T_train = T_train_changed)\n",
    "\n",
    "# p = 5\n",
    "model_p5, w_vector_5 = regressor.modelTrain(X_train = X_train_p5, T_train = T_train_changed)\n",
    "\n",
    "# p = 6\n",
    "model_p6, w_vector_6 = regressor.modelTrain(X_train = X_train_p6, T_train = T_train_changed)\n",
    "\n",
    "# p = 7\n",
    "model_p7, w_vector_7 = regressor.modelTrain(X_train = X_train_p7, T_train = T_train_changed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Test Accuracy for lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy_test_p1 = regressor.predictTrain(X=X_test_p1, T=T_test_changed, n = n_test, p = 1, model=model_p1, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p2 = regressor.predictTrain(X=X_test_p2, T=T_test_changed, n = n_test, p = 2, model=model_p2, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p3 = regressor.predictTrain(X=X_test_p3, T=T_test_changed, n = n_test, p = 3, model=model_p3, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p4 = regressor.predictTrain(X=X_test_p4, T=T_test_changed, n = n_test, p = 4, model=model_p4, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p5 = regressor.predictTrain(X=X_test_p5, T=T_test_changed, n = n_test, p = 5, model=model_p5, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p6 = regressor.predictTrain(X=X_test_p6, T=T_test_changed, n = n_test, p = 6, model=model_p6, datasetName = \"Test Data\", printFlag = True)\n",
    "_, accuracy_test_p7 = regressor.predictTrain(X=X_test_p7, T=T_test_changed, n = n_test, p = 7, model=model_p7, datasetName = \"Test Data\", printFlag = True)\n",
    "\n",
    "test_acc_l0 = [accuracy_test_p1, accuracy_test_p2, accuracy_test_p3, accuracy_test_p4, accuracy_test_p5, accuracy_test_p6, accuracy_test_p7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model using sklearn's Ridge Class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] i. Report the classification accuracy on the training and test sets for each value of p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha (or) lambda values list\n",
    "lambda_List = [0.3, 1, 3, 10, 30, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_acc_l0 = [77.0, 84.5, 81.5, 71.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p1 = {}\n",
    "J_p1 = {}\n",
    "\n",
    "y_hat_train_p1 = {}\n",
    "accuracy_train_p1 = {}\n",
    "\n",
    "y_hat_test_p1 = {}\n",
    "accuracy_test_p1 = {}\n",
    "\n",
    "accuracy_test_p1[0] = test_acc_l0[0]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p1, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p1[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p1, T=T_train_changed, n = n_train, p = 1, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p1[lambd_a] = y_hat_train\n",
    "    accuracy_train_p1[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p1, T=T_test_changed, n = n_test, p = 1, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p1[lambd_a] = y_hat_test\n",
    "    accuracy_test_p1[lambd_a] = acc_test\n",
    "\n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p1[lambd_a] = J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p2 = {}\n",
    "J_p2 = {}\n",
    "\n",
    "y_hat_train_p2 = {}\n",
    "accuracy_train_p2 = {}\n",
    "\n",
    "y_hat_test_p2 = {}\n",
    "accuracy_test_p2 = {}\n",
    "\n",
    "accuracy_test_p2[0] = test_acc_l0[1]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p2, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p2[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p2, T=T_train_changed, n = n_train, p = 2, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p2[lambd_a] = y_hat_train\n",
    "    accuracy_train_p2[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p2, T=T_test_changed, n = n_test, p = 2, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p2[lambd_a] = y_hat_test\n",
    "    accuracy_test_p2[lambd_a] = acc_test\n",
    "    \n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p2[lambd_a] = J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p3 = {}\n",
    "J_p3 = {}\n",
    "\n",
    "y_hat_train_p3 = {}\n",
    "accuracy_train_p3 = {}\n",
    "\n",
    "y_hat_test_p3 = {}\n",
    "accuracy_test_p3 = {}\n",
    "\n",
    "accuracy_test_p3[0] = test_acc_l0[2]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p3, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p3[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p3, T=T_train_changed, n = n_train, p = 3, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p3[lambd_a] = y_hat_train\n",
    "    accuracy_train_p3[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p3, T=T_test_changed, n = n_test, p = 3, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p3[lambd_a] = y_hat_test\n",
    "    accuracy_test_p3[lambd_a] = acc_test\n",
    "\n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p3[lambd_a] = J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p4 = {}\n",
    "J_p4 = {}\n",
    "\n",
    "y_hat_train_p4 = {}\n",
    "accuracy_train_p4 = {}\n",
    "\n",
    "y_hat_test_p4 = {}\n",
    "accuracy_test_p4 = {}\n",
    "\n",
    "accuracy_test_p4[0] = test_acc_l0[3]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p4, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p4[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p4, T=T_train_changed, n = n_train, p = 4, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p4[lambd_a] = y_hat_train\n",
    "    accuracy_train_p4[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p4, T=T_test_changed, n = n_test, p = 4, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p4[lambd_a] = y_hat_test\n",
    "    accuracy_test_p4[lambd_a] = acc_test\n",
    "\n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p4[lambd_a] = J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p5 = {}\n",
    "J_p5 = {}\n",
    "\n",
    "y_hat_train_p5 = {}\n",
    "accuracy_train_p5 = {}\n",
    "\n",
    "y_hat_test_p5 = {}\n",
    "accuracy_test_p5 = {}\n",
    "\n",
    "accuracy_test_p5[0] = test_acc_l0[4]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p5, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p5[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p5, T=T_train_changed, n = n_train, p = 5, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p5[lambd_a] = y_hat_train\n",
    "    accuracy_train_p5[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p5, T=T_test_changed, n = n_test, p = 5, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p5[lambd_a] = y_hat_test\n",
    "    accuracy_test_p5[lambd_a] = acc_test\n",
    "\n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p5[lambd_a] = J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p6 = {}\n",
    "J_p6 = {}\n",
    "\n",
    "y_hat_train_p6 = {}\n",
    "accuracy_train_p6 = {}\n",
    "\n",
    "y_hat_test_p6 = {}\n",
    "accuracy_test_p6 = {}\n",
    "\n",
    "accuracy_test_p6[0] = test_acc_l0[5]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p6, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p6[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p6, T=T_train_changed, n = n_train, p = 6, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p6[lambd_a] = y_hat_train\n",
    "    accuracy_train_p6[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p6, T=T_test_changed, n = n_test, p = 6, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p6[lambd_a] = y_hat_test\n",
    "    accuracy_test_p6[lambd_a] = acc_test\n",
    "    \n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p6[lambd_a] = J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing training for various values of lambda for the value of degree (p) = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p7 = {}\n",
    "J_p7 = {}\n",
    "\n",
    "y_hat_train_p7 = {}\n",
    "accuracy_train_p7 = {}\n",
    "\n",
    "y_hat_test_p7 = {}\n",
    "accuracy_test_p7 = {}\n",
    "\n",
    "accuracy_test_p7[0] = test_acc_l0[6]\n",
    "\n",
    "for lambd_a in lambda_List:\n",
    "    model, _ = regressor.modelTrain_Regularization(X_train = X_train_p7, T_train = T_train_changed, lambd_a = lambd_a)\n",
    "    model_p7[lambd_a] = model\n",
    "    print()\n",
    "\n",
    "    y_hat_train, acc_train = regressor.predictTrain(X=X_train_p7, T=T_train_changed, n = n_train, p = 7, model=model, datasetName = f\"Train Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_train_p7[lambd_a] = y_hat_train\n",
    "    accuracy_train_p7[lambd_a] = acc_train\n",
    "    \n",
    "    y_hat_test, acc_test = regressor.predictTrain(X=X_test_p7, T=T_test_changed, n = n_test, p = 7, model=model, datasetName = f\"Test Data lambda = {lambd_a}\", printFlag = False)\n",
    "    y_hat_test_p7[lambd_a] = y_hat_test\n",
    "    accuracy_test_p7[lambd_a] = acc_test\n",
    "    \n",
    "    J = regressor.computeCostRegularized(T_train=T_train_changed, Y_hat=y_hat_train, lambd_a = lambd_a, model=model)\n",
    "    J_p7[lambd_a] = J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.printAccuracy(accuracy_train_p1, accuracy_test_p1, p = 1)\n",
    "regressor.printAccuracy(accuracy_train_p2, accuracy_test_p2, p = 2)\n",
    "regressor.printAccuracy(accuracy_train_p3, accuracy_test_p3, p = 3)\n",
    "regressor.printAccuracy(accuracy_train_p4, accuracy_test_p4, p = 4)\n",
    "regressor.printAccuracy(accuracy_train_p5, accuracy_test_p5, p = 5)\n",
    "regressor.printAccuracy(accuracy_train_p6, accuracy_test_p6, p = 6)\n",
    "regressor.printAccuracy(accuracy_train_p7, accuracy_test_p7, p = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] ii. Plot the training data points and the decision regions for p = 1,2,4,7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 1\n",
    "print(\"Plot for p = 1 and lambda = 1\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=1, model=model_p1[1])\n",
    "\n",
    "print(\"Plot for p = 1 and lambda = 10\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=1, model=model_p1[10])\n",
    "\n",
    "print(\"Plot for p = 1 and lambda = 100\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=1, model=model_p1[100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for p = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 1\n",
    "print(\"Plot for p = 2 and lambda = 1\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=2, model=model_p2[1])\n",
    "\n",
    "print(\"Plot for p = 2 and lambda = 10\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=2, model=model_p2[10])\n",
    "\n",
    "print(\"Plot for p = 2 and lambda = 100\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=2, model=model_p2[100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for p = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 4\n",
    "print(\"Plot for p = 4 and lambda = 1\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=4, model=model_p4[1])\n",
    "\n",
    "print(\"Plot for p = 4 and lambda = 10\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=4, model=model_p4[10])\n",
    "\n",
    "print(\"Plot for p = 4 and lambda = 100\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=4, model=model_p4[100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for p = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 7\n",
    "print(\"Plot for p = 7 and lambda = 1\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=7, model=model_p7[1])\n",
    "\n",
    "print(\"Plot for p = 7 and lambda = 10\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=7, model=model_p7[10])\n",
    "\n",
    "print(\"Plot for p = 7 and lambda = 100\")\n",
    "regressor.plotNonLinear(X_train=X_train, T_train = T_train.reshape(n_train,), degree=7, model=model_p7[100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] iii. Plot the train and test accuracy vs. lambda for all p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all accuracies together \n",
    "train_Accuracy_All = []\n",
    "test_Accuracy_All = []\n",
    "J_All = []\n",
    "\n",
    "for d in [accuracy_train_p1, accuracy_train_p2, accuracy_train_p3, accuracy_train_p4, accuracy_train_p5, accuracy_train_p6, accuracy_train_p7]:\n",
    "    train_Accuracy_All.append(list(d.values()))\n",
    "\n",
    "for d in [accuracy_test_p1, accuracy_test_p2, accuracy_test_p3, accuracy_test_p4, accuracy_test_p5, accuracy_test_p6, accuracy_test_p7]:\n",
    "    test_Accuracy_All.append(list(d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list = list(zip(*train_Accuracy_All))\n",
    "train_Accuracy_All = transposed_list\n",
    "\n",
    "\n",
    "transposed_list = list(zip(*test_Accuracy_All))\n",
    "test_Accuracy_All = transposed_list\n",
    "\n",
    "transposed_list = list(zip(*J_All))\n",
    "J_All = transposed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.plotAccuracyRegularized(lambda_List, train_Accuracy_All, test_Accuracy_All)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] iv. Plot JMSE vs. p for all values of p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_All = []\n",
    "for d in [J_p1, J_p2, J_p3, J_p4, J_p5, J_p6, J_p7]:\n",
    "    J_All.append(list(d.values()))\n",
    "\n",
    "transposed_list = list(zip(*J_All))\n",
    "J_All = transposed_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.plotCostRegularized(lambda_List, J_All)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] (e) Additionally, plot test accuracy vs. log (ùúÜ), for ùëù = 1,2,4,7 on a single plot. Use log base 10. (Also consider ùúÜ = 0 case, which will be your results from part (a).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Accuracy_All = []\n",
    "\n",
    "for d in [accuracy_test_p1, accuracy_test_p2, accuracy_test_p4, accuracy_test_p7]:\n",
    "    test_Accuracy_All.append(list(d.values()))\n",
    "\n",
    "test_Accuracy_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.plotTestAccuracyVsLambda(lambda_List, test_Accuracy_All)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] (f) Compare and comment on the results in part (d) and how they relate to results from part (a). Do you see any effect of regularization? Explain briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yes, I can clearly see the effect of regularization.\n",
    "\n",
    "We can clearly see that the model now generalizes well when we add the regularization term to the loss. We should also note that the performance is almost same for small lambda values like 0.3, 1 and 3. The model has a very good performance on both the test and train datasets for the regularization lambda = 10. At this value of lambda the model performs well for all values of p from p = 1 to 7.\n",
    "\n",
    "We should be very careful with lambda because for larger values of lambda the cost penalizes the weights more and the performance is bad for lower order polynomials like p = 1 through 4. For higher order polynomials the model has a good fit on the training and it avaoids overfitting and hence it performs really well on p = 7 with lambda = 100.\n",
    "\n",
    "The key take away is that, lambda values should neither be very small nor very large because in case one we can expect the model to overfit on the training data for higher values of p. And in the second case we can expect the model to have a good fit for p = 6, 7, etc whereas it under-fits for p from 0 to 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2] (g) Study the sklearn LinearRegression / Ridge class and explain how to obtain the trained weight vector. The weight vector can be used to write the equation of the decision boundary / the decision rule. Give the decision rule for ùëù = 2 in part (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The weight vector can be obtained as follows:\n",
    "\n",
    "#### LR_Regularized = Ridge(alpha = lambd_a, fit_intercept = False)\n",
    "#### model_R = LR_Regularized.fit(X_train, T_train)\n",
    "#### w_vector = model_R.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The decision rule for p = 2 in part (a):\n",
    "\n",
    "### w0 + (w1 * x1) + (w2* x2) + (w3 * x1^2) + (w4 * x1x2) + (w5 * x2^2) = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
